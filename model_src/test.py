import os
import sys
import numpy as np
import traceback

from config import RAW_DATA_DIR, UPLOAD_DATA_DIR, RESULT_DIR, MODEL_DIR, MAE_THRESHOLD, RMSE_THRESHOLD
from data_loader import load_and_process_new_data, load_combined_data, get_latest_input_from_raw
from material_forecast_model import MaterialForecastModel
from train import train_single_fish
from utils import (
    load_scaler, save_scaler, calculate_metrics, needs_retraining,
    plot_prediction, get_img, inverse_transform_target_only
)
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

load_dotenv()

# Define targets
targets = {
    "ê´‘ì–´": "ê´‘ì–´ ì†Œë¹„ëŸ‰(g)",
    "ì—°ì–´": "ì—°ì–´ ì†Œë¹„ëŸ‰(g)",
    "ì¥ì–´": "ì¥ì–´ ì†Œë¹„ëŸ‰(g)"
}

def main(upload_filename):
    try:
        results = {}
        upload_path = os.path.join(UPLOAD_DATA_DIR, upload_filename)

        for fish_name, target_column in targets.items():
            print(f"\nğŸ” Processing {fish_name}...")

            # 1. Load 7-day uploaded data (no sequence generation)
            try:
                X_true_data, y_true_data, _ = load_and_process_new_data(upload_path, target_column)
            except Exception as e:
                results[f"{fish_name}_ì˜¤ë¥˜"] = f"ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {str(e)}"
                continue

            # 2. Load model & recent data & scaler
            raw_file_path = os.path.join(RAW_DATA_DIR, "qooqoo_dummy_v0.12.csv")

            try:
                model = MaterialForecastModel.load(fish_name)
                X_input, scaler = get_latest_input_from_raw(raw_file_path, target_column)
            except Exception as e:
                print(f"âš ï¸ Model not found for {fish_name}. Skipping.")
                results[f"{fish_name}_ì˜¤ë¥˜"] = str(e)
                continue

            # 3. Predict
            y_pred = model.predict(X_input)[0]
            mae, rmse = calculate_metrics(y_true_data, y_pred)
            print(f"ğŸ“Š MAE: {mae:.2f}, RMSE: {rmse:.2f}")

            retrained = False

            # 4. Check if retraining is needed
            if needs_retraining(mae, rmse, MAE_THRESHOLD, RMSE_THRESHOLD):
                print(f"ğŸ” Retraining {fish_name} using combined 90-day dataset...")
                retrained = True

                X_finetune, y_finetune, scaler = load_combined_data(
                    raw_file_path, upload_path, target_column
                )

                # ğŸ” Train again (fine-tune style)
                train_single_fish(fish_name, target_column, raw_file_path, X=X_finetune, y=y_finetune, scaler=scaler)

                # Reload model and predict again
                model = MaterialForecastModel.load(fish_name)
                X_input, scaler = get_latest_input_from_raw(raw_file_path, target_column)
                y_pred = model.predict(X_input)
                retrained = True

            # 5. Plot prediction image
            result_dir = os.path.join(RESULT_DIR, fish_name)
            os.makedirs(result_dir, exist_ok=True)
            img_path = os.path.join(result_dir, "sample_prediction_debug.png")
            plot_prediction(y_true_data[:1], y_pred[:1], img_path, scaler, target_column)
            encoded_img = get_img(img_path)

            # 6. Inverse transform for total prediction
            y_pred_rescaled = inverse_transform_target_only(y_pred, scaler)
            total_prediction = int(np.sum(y_pred_rescaled))


            # Store results
            results[f"{fish_name}_ê²°ê³¼_ì´ë¯¸ì§€"] = encoded_img
            results[f"{fish_name}_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡"] = total_prediction
            results[f"{fish_name}_ì¬í•™ìŠµ_ì—¬ë¶€"] = int(retrained)

        # 7. Generate LLM report
        system_message = (
            "ë„ˆëŠ” ë°ì´í„°ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ì´í›„ 7ì¼ ì¬ë£Œ ë°œì£¼ëŸ‰ì„ ì˜ˆì¸¡í•˜ê³  "
            "ê·¸ ê²°ê³¼ì— ëŒ€í•´ì„œ ë³´ê³ ì„œ í˜•íƒœë¡œ ì¶œë ¥í•˜ëŠ” ì—…ë¬´ë¥¼ ìˆ˜í–‰í•´. "
            "ë³´ê³ ì„œì—ëŠ” ê° ì¬ë£Œë³„ ì¼ìë³„ ë°œì£¼ëŸ‰ ì˜ˆì¸¡ì¹˜ë¥¼ í‘œ í˜•ì‹ ë˜ëŠ” ì •ë¦¬ëœ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì œì‹œí•˜ê³ , "
            "ì¶”ì„¸ë‚˜ íŠ¹ì´ì‚¬í•­ì´ ìˆë‹¤ë©´ ê°„ë‹¨í•œ ì½”ë©˜íŠ¸ë„ í¬í•¨í•´ì¤˜."
        )
        user_input = f"""
        ë‹¤ìŒì€ 3ê°€ì§€ ì¬ë£Œ(ê´‘ì–´, ì—°ì–´, ì¥ì–´)ì˜ 1ì£¼ì¼(7ì¼) ê°„ ë°œì£¼ëŸ‰ ì˜ˆì¸¡ ê²°ê³¼ì…ë‹ˆë‹¤:

        ê´‘ì–´_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡:
        {results["ê´‘ì–´_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡"]}

        ì—°ì–´_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡:
        {results["ì—°ì–´_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡"]}

        ì¥ì–´_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡:
        {results["ì¥ì–´_1ì£¼_ë°œì£¼ëŸ‰ ì˜ˆì¸¡"]}

        ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.

        line ê¸°ì¤€ìœ¼ë¡œ 10ì¤„ ì´ë‚´ë¡œ ì‘ì„±í•´ì¤˜
        """

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            ("human", "{input}")
        ])
        llm = ChatOpenAI(temperature=0)
        chain = prompt | llm
        response = chain.invoke({"input": user_input})

        results["ë³´ê³ ì„œ"] = response.content

        print("\nğŸ“ Generated Report:\n")
        print(response.content)

    except Exception as e:
        print("âŒ Error occurred:")
        traceback.print_exc()


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python debug_predict.py <csv_file>")
        sys.exit(1)

    input_csv = sys.argv[1]
    main(input_csv)
